<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Pedro's Blog</title><link>https://pedrovhb.com/</link><description>Recent content on Pedro's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>pedrovhb@gmail.com (Pedro Batista)</managingEditor><webMaster>pedrovhb@gmail.com (Pedro Batista)</webMaster><lastBuildDate>Sun, 20 Jun 2021 17:24:16 -0300</lastBuildDate><atom:link href="https://pedrovhb.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Probabilistic data structures - bloom filters</title><link>https://pedrovhb.com/posts/probabilistic_data_structures/</link><pubDate>Sun, 20 Jun 2021 17:24:16 -0300</pubDate><author>pedrovhb@gmail.com (Pedro Batista)</author><guid>https://pedrovhb.com/posts/probabilistic_data_structures/</guid><description>Traditionally in programming we think about 0s and 1s as being infallible. They either are, or aren&amp;rsquo;t, and other than for cosmic rays flipping bits in RAM (it happens) there&amp;rsquo;s not much margin for uncertainty. It&amp;rsquo;s one of the nice things about computers: our memory is imperfect, but theirs isn&amp;rsquo;t.
What if we could trade off a bit of this consistency for a lot of performance, though? Well, it turns out that we sometimes can, by using probabilistic data structures.</description></item></channel></rss>