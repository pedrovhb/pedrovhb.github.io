<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Pedro's Blog</title><link>https://pedrovhb.com/posts/</link><description>Recent content in Posts on Pedro's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>pedrovhb@gmail.com (Pedro Batista)</managingEditor><webMaster>pedrovhb@gmail.com (Pedro Batista)</webMaster><lastBuildDate>Mon, 05 Jul 2021 15:04:32 -0300</lastBuildDate><atom:link href="https://pedrovhb.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Fast reshaping with iterators</title><link>https://pedrovhb.com/posts/fast_reshaping_with_iterators/</link><pubDate>Mon, 05 Jul 2021 15:04:32 -0300</pubDate><author>pedrovhb@gmail.com (Pedro Batista)</author><guid>https://pedrovhb.com/posts/fast_reshaping_with_iterators/</guid><description>Lately I&amp;rsquo;ve been reading up a bit more on functional programming. I feel that after years of knowing about the existence of the paradigm and even trying to dip my toes in a couple of times without success, now it finally &amp;ldquo;clicked&amp;rdquo;.
I&amp;rsquo;m still playing around with concepts and languages, and trying to look at some programming exercises in a more functional light. It was surprising to me, though, how easily and efficiently I was able to solve today&amp;rsquo;s LeetCode challenge.</description></item><item><title>Probabilistic data structures - bloom filters</title><link>https://pedrovhb.com/posts/probabilistic_data_structures/</link><pubDate>Sun, 20 Jun 2021 17:24:16 -0300</pubDate><author>pedrovhb@gmail.com (Pedro Batista)</author><guid>https://pedrovhb.com/posts/probabilistic_data_structures/</guid><description>Traditionally in programming we think about 0s and 1s as being infallible. They either are, or aren&amp;rsquo;t, and other than for cosmic rays flipping bits in RAM (it happens) there&amp;rsquo;s not much margin for uncertainty. It&amp;rsquo;s one of the nice things about computers: our memory is imperfect, but theirs isn&amp;rsquo;t.
What if we could trade off a bit of this consistency for a lot of performance, though? Well, it turns out that we sometimes can, by using probabilistic data structures.</description></item></channel></rss>